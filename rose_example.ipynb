{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a45ec6d7-5e1e-406a-850c-1dfc591ca18b",
   "metadata": {},
   "source": [
    "This is about how things work for surrogate AL. First make sure that you have the correct env setup. On Perlmutter this is done by \n",
    "```\n",
    "module load conda\n",
    "conda create --prefix /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose python=3.11\n",
    "conda activate /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose\n",
    "pip install radical.pilot\n",
    "radical-stack\n",
    "\n",
    "# Install radical.flow\n",
    "# Don't forget to install dask!!\n",
    "pip install dask\n",
    "pip install \"dask[distributed]\" --upgrade\n",
    "\n",
    "cd /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/radical.flow\n",
    "##### Modify code in radical flow #####\n",
    "pip install -e .\n",
    "\n",
    "# also need to copy the version file:\n",
    "cp /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/radical.flow/VERSION /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/radical.flow/src/radical/flow/\n",
    "\n",
    "#Otherwise see the following error message:\n",
    "#Traceback (most recent call last):\n",
    "#  File \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/rose_github/rose_experiment/run_me_async.py\", line 5, in <module>\n",
    "#    from rose.learner import ActiveLearner\n",
    "#  File \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/rose_github/rose/__init__.py\", line 2, in <module>\n",
    "#    from rose.learner import ActiveLearner\n",
    "#  File \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/rose_github/rose/learner.py\", line 8, in <module>\n",
    "#    from radical.flow import RadicalExecutionBackend, WorkflowEngine\n",
    "#  File \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/radical.flow/src/radical/flow/__init__.py\", line 20, in <module>\n",
    "#    = _ru.get_version(_mod_root)\n",
    "#      ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
    "#  File \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/utils/get_version.py\", line 72, in get_version\n",
    "#    raise RuntimeError(\"Cannot determine version from %s (%s)\"\n",
    "#RuntimeError: Cannot determine version from ['/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/radical.flow/src/radical/flow'] (FileNotFoundError(2, 'No such file or directory'))\n",
    "\n",
    "# Install rose\n",
    "git clone https://github.com/radical-cybertools/ROSE.git rose_github\n",
    "cd rose_github/\n",
    "git checkout feature/rose_radical.flow\n",
    "pip install -e .\n",
    "\n",
    "mkdir rose_experiment; cd rose_experiment\n",
    "\n",
    "\n",
    "# For nano-confinement project, add the following dependency:\n",
    "pip install GPy\n",
    "pip3 install torch torchvision torchaudio\n",
    "\n",
    "# To expose this to jupyter notebook at jupyterlab on Perlmutter, do the following:\n",
    "conda install ipykernel\n",
    "python -m ipykernel install --user --name rose --display-name \"Python ROSE conda env\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a18c5e-a273-4796-97a2-32444891dde0",
   "metadata": {},
   "source": [
    "I didn't change the content of `model/model.py`, but did code refactoring for Fanbo's notebook and get the following five files:\n",
    "```\n",
    "train.py\n",
    "This is the training task in terms of rose\n",
    "\n",
    "active.py\n",
    "This is the active learning task in terms of rose\n",
    "\n",
    "bootstrap.py\n",
    "This is the dataset preparing task. Run it only once (currently for each pipeline need to run it once, but actually we don't need that, so need to reorganize code a bit in the future)\n",
    "\n",
    "run_rose.py\n",
    "This is the main rose interface, about how we run parallel pipelines\n",
    "\n",
    "utils.py\n",
    "This is some helping function copy and paste from Fanbo's code\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b45d177-4acb-4dc7-be16-34bc86c9da35",
   "metadata": {},
   "source": [
    "Currently to enable multiple pipelines running at the same time, I use a config file to control for each pipeline, the hyper-parameter for training/active learning. This is in `config/xxx.yaml`. \n",
    "\n",
    "Basically the model type could also be merged into this file but I have not done that.\n",
    "\n",
    "Then if we want to run, for example, n pipelines at the same time, we just need to prepare n config files, one for each pipeline.\n",
    "\n",
    "One important change compared with Fanbo is, we need to save and load model between task. Earlier there is a bug with gpr model saving but it is fixed now using Gpy's API. For bnn, I have not fully tested it, and there could be bug with pickle and CPU/GPU transfer.\n",
    "\n",
    "Another important change is the data. Similarly the training dataset and the remaining dataset need to be saved after active learning task and read in training task. Of course an alternative way to do that is to use a fixed input, and only save index instead of the value. However as in the future we want to include real simulation, saving dataset will make it more forward compatible.\n",
    "\n",
    "Below is the typical filesystem hierarchy in output dir:\n",
    "```\n",
    "workflow_root_dir\n",
    "-pipeline_dir_1 controled by config, model\n",
    "-pipeline_dir_2\n",
    "-pipeline_dir_n\n",
    "    -iter_001: test_data, train_data, remaining_data, model.ckpt, metric.json\n",
    "\t-iter_m: train_data, remaining_data, model.ckpt, metric.json\n",
    "```\n",
    "\n",
    "Notice here for each pipeline, the test data only have one copy, which is saved in iter_001 folder, and train_data, remaining_data will be saved in all iter_xxx folder (they will be different as iteration increase). \n",
    "\n",
    "In addition to the data, each iter_xx folder also saves the model and metric for reprod and later data processing.\n",
    "\n",
    "Currently there is still some minor changes I need to make, for each, gpr takes a n_new_sample, but it should be merged into config.\n",
    "\n",
    "Now you can start executing the run_rose.py. Here I just copy and paste the content here and execute it in notebook, but normally running in cmd on HPC cluster should be preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e29cc62-4304-41a7-a103-5e6fbcafa9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  python               : /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/bin/python3\n",
      "  pythonpath           : /opt/nersc/pymon\n",
      "  version              : 3.11.11\n",
      "  virtualenv           : /pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose\n",
      "\n",
      "  radical.analytics    : 1.101.0\n",
      "  radical.gtod         : 1.100.1\n",
      "  radical.pilot        : 1.102.0\n",
      "  radical.utils        : 1.100.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!source ../../conda_rose.sh\n",
    "#%env RADICAL_REPORT=FALSE\n",
    "#%env RADICAL_LOG_LVL=DEBUG\n",
    "#%env RADICAL_PROFILE=TRUE\n",
    "#%env RADICAL_SMT=1\n",
    "#!which python\n",
    "#!python -V\n",
    "#!radical-stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb915223-58b9-4528-ad0f-4433c3f61c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5ff7159-4f2c-4f5f-a7cc-7c43ac14d92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resource Engine Failed to start, terminating\n",
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'radical-pilot-bridge'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrose\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlearner\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ActiveLearner\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrose\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mengine\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Task, ResourceEngine\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m engine = ResourceEngine({\u001b[33m'\u001b[39m\u001b[33mresource\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mnersc.perlmutter_gpu\u001b[39m\u001b[33m'\u001b[39m, \n\u001b[32m      9\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mruntime\u001b[39m\u001b[33m'\u001b[39m : \u001b[32m60\u001b[39m, \n\u001b[32m     10\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33maccess_schema\u001b[39m\u001b[33m'\u001b[39m:\u001b[33m'\u001b[39m\u001b[33minteractive\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     11\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mproject\u001b[39m\u001b[33m'\u001b[39m : \u001b[33m\"\u001b[39m\u001b[33mm2616_g\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mcores\u001b[39m\u001b[33m'\u001b[39m   : \u001b[32m64\u001b[39m, \n\u001b[32m     13\u001b[39m                          \u001b[33m'\u001b[39m\u001b[33mgpus\u001b[39m\u001b[33m'\u001b[39m    : \u001b[32m4\u001b[39m})\n\u001b[32m     15\u001b[39m learner = ActiveLearner(engine=engine)\n\u001b[32m     16\u001b[39m code_path = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msys.executable\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos.getcwd()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/rose_github/rose/engine.py:88\u001b[39m, in \u001b[36m__init__\u001b[39m\u001b[34m(self, resources)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;129m@typeguard\u001b[39m.typechecked\n\u001b[32m     86\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, resources: Dict) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     87\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m         \u001b[38;5;28mself\u001b[39m._session = rp.Session(uid=ru.generate_id(\u001b[33m'\u001b[39m\u001b[33mrose.session\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     89\u001b[39m                                                       mode=ru.ID_PRIVATE))\n\u001b[32m     90\u001b[39m         \u001b[38;5;28mself\u001b[39m.task_manager = rp.TaskManager(\u001b[38;5;28mself\u001b[39m._session)\n\u001b[32m     91\u001b[39m         \u001b[38;5;28mself\u001b[39m.pilot_manager = rp.PilotManager(\u001b[38;5;28mself\u001b[39m._session)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/pilot/session.py:191\u001b[39m, in \u001b[36mSession.__init__\u001b[39m\u001b[34m(self, proxy_url, uid, cfg, _role, _reg_addr, **close_options)\u001b[39m\n\u001b[32m    187\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mnon-primary session needs UID (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m'\u001b[39m % \u001b[38;5;28mself\u001b[39m._role)\n\u001b[32m    189\u001b[39m \u001b[38;5;66;03m# initialization is different for each session type\u001b[39;00m\n\u001b[32m    190\u001b[39m \u001b[38;5;66;03m# NOTE: we could refactor this to session sub-classes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m   \u001b[38;5;28mself\u001b[39m._role == \u001b[38;5;28mself\u001b[39m._PRIMARY: \u001b[38;5;28mself\u001b[39m._init_primary()\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._role == \u001b[38;5;28mself\u001b[39m._AGENT_0: \u001b[38;5;28mself\u001b[39m._init_agent_0()\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._role == \u001b[38;5;28mself\u001b[39m._AGENT_N: \u001b[38;5;28mself\u001b[39m._init_agent_n()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/pilot/session.py:254\u001b[39m, in \u001b[36mSession._init_primary\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28mself\u001b[39m._publish_cfg()\n\u001b[32m    253\u001b[39m \u001b[38;5;66;03m# start bridges and components\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m \u001b[38;5;28mself\u001b[39m._start_components()\n\u001b[32m    256\u001b[39m \u001b[38;5;66;03m# primary session hooks into the control pubsub\u001b[39;00m\n\u001b[32m    257\u001b[39m bcfg = \u001b[38;5;28mself\u001b[39m._reg[\u001b[33m'\u001b[39m\u001b[33mbridges.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m % rpc.CONTROL_PUBSUB]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/pilot/session.py:811\u001b[39m, in \u001b[36mSession._start_components\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    808\u001b[39m \u001b[38;5;66;03m# primary sessions and agents have a component manager\u001b[39;00m\n\u001b[32m    809\u001b[39m \u001b[38;5;66;03m# 'self._cmgr.close()` should be called during termination\u001b[39;00m\n\u001b[32m    810\u001b[39m \u001b[38;5;28mself\u001b[39m._cmgr = rpu.ComponentManager(\u001b[38;5;28mself\u001b[39m.uid, \u001b[38;5;28mself\u001b[39m.reg_addr, \u001b[38;5;28mself\u001b[39m._uid)\n\u001b[32m--> \u001b[39m\u001b[32m811\u001b[39m \u001b[38;5;28mself\u001b[39m._cmgr.start_bridges(\u001b[38;5;28mself\u001b[39m._cfg.bridges)\n\u001b[32m    812\u001b[39m \u001b[38;5;28mself\u001b[39m._cmgr.start_components(\u001b[38;5;28mself\u001b[39m._cfg.components)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/pilot/utils/component_manager.py:147\u001b[39m, in \u001b[36mComponentManager.start_bridges\u001b[39m\u001b[34m(self, bridges)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28mself\u001b[39m._reg[\u001b[33m'\u001b[39m\u001b[33mbridges.\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.cfg\u001b[39m\u001b[33m'\u001b[39m % bname] = bcfg\n\u001b[32m    144\u001b[39m cmd = \u001b[33m'\u001b[39m\u001b[33mradical-pilot-bridge \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m \\\n\u001b[32m    145\u001b[39m     % (\u001b[38;5;28mself\u001b[39m._sid, \u001b[38;5;28mself\u001b[39m._reg.url, bname, os.getpid())\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m out, err, ret = ru.sh_callout(cmd, cwd=\u001b[38;5;28mself\u001b[39m._cfg.path)\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret:\n\u001b[32m    150\u001b[39m     msg = \u001b[33m'\u001b[39m\u001b[33mbridge startup failed [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m] [\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m'\u001b[39m, out, err\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/site-packages/radical/utils/shell.py:58\u001b[39m, in \u001b[36msh_callout\u001b[39m\u001b[34m(cmd, stdout, stderr, shell, env, cwd)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stderr   : stderr = sp.PIPE\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m        : stderr = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m p = sp.Popen(cmd, stdout=stdout, stderr=stderr,\n\u001b[32m     59\u001b[39m                   shell=shell, env=env, cwd=cwd)\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stdout \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stderr:\n\u001b[32m     62\u001b[39m     ret = p.wait()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/subprocess.py:1026\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1022\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1023\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1024\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28mself\u001b[39m._execute_child(args, executable, preexec_fn, close_fds,\n\u001b[32m   1027\u001b[39m                         pass_fds, cwd, env,\n\u001b[32m   1028\u001b[39m                         startupinfo, creationflags, shell,\n\u001b[32m   1029\u001b[39m                         p2cread, p2cwrite,\n\u001b[32m   1030\u001b[39m                         c2pread, c2pwrite,\n\u001b[32m   1031\u001b[39m                         errread, errwrite,\n\u001b[32m   1032\u001b[39m                         restore_signals,\n\u001b[32m   1033\u001b[39m                         gid, gids, uid, umask,\n\u001b[32m   1034\u001b[39m                         start_new_session, process_group)\n\u001b[32m   1035\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1036\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/conda_env/rose/lib/python3.11/subprocess.py:1955\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1953\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1954\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1955\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1956\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1957\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'radical-pilot-bridge'"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "\n",
    "import radical.pilot as rp\n",
    "\n",
    "from rose.learner import ActiveLearner\n",
    "from rose.engine import Task, ResourceEngine\n",
    "\n",
    "engine = ResourceEngine({'resource': 'nersc.perlmutter_gpu', \n",
    "                         'runtime' : 60, \n",
    "                         'access_schema':'interactive',\n",
    "                         'project' : \"m2616_g\",\n",
    "                         'cores'   : 64, \n",
    "                         'gpus'    : 4})\n",
    "\n",
    "learner = ActiveLearner(engine=engine)\n",
    "code_path = f'{sys.executable} {os.getcwd()}'\n",
    "\n",
    "#FIXME!! I am utility task!!\n",
    "@learner.simulation_task\n",
    "def bootstrap(*args, pipeline_dir, input_data_dir):\n",
    "    return Task(executable=f'{code_path}/bootstrap.py --pipeline_dir {pipeline_dir} --input_data_dir {input_data_dir}')\n",
    "    \n",
    "#FIXME!! For this two tasks, need to specify if using GPU, and other variables!!\n",
    "@learner.training_task\n",
    "def training(*args, model, config_file, iteration, pipeline_dir):\n",
    "    return Task(executable=f'{code_path}/train.py --model {model} --config {config_file} --iteration {iteration} --pipeline_dir {pipeline_dir}')\n",
    "\n",
    "@learner.active_learn_task\n",
    "def active_learning(*args, model, config_file, iteration, pipeline_dir, num_new_samples):\n",
    "    return Task(executable=f'{code_path}/active.py --model {model} --config {config_file} --iteration {iteration} --pipeline_dir {pipeline_dir} --n_new_samples {num_new_samples}')\n",
    "\n",
    "def teach_single_pipeline(model, input_data_dir, config_file, pipeline_dir, num_iter, num_new_samples):\n",
    "    iter_id = 1\n",
    "    print(\"Start doing bootstrap (only once!)\")\n",
    "    bs = bootstrap(pipeline_dir=pipeline_dir, input_data_dir=input_data_dir)\n",
    "    bs.result()\n",
    "    while iter_id < num_iter:   # n iter means in total n traning and n-1 al\n",
    "        print(f\"Start doing iteration {iter_id}\")\n",
    "        train = training(model=model, config_file=config_file, iteration=iter_id, pipeline_dir=pipeline_dir)\n",
    "        if iter_id == num_iter - 1:\n",
    "            train.result()\n",
    "        else:\n",
    "            active_learn = active_learning(train, model=model, config_file=config_file, iteration=iter_id, pipeline_dir=pipeline_dir, num_new_samples=num_new_samples)\n",
    "            active_learn.result()\n",
    "        iter_id += 1\n",
    "\n",
    "def teach():\n",
    "    submitted_pipelines = []\n",
    "    async_pipeline = learner.as_async(teach_single_pipeline)\n",
    "    model = \"gpr\"\n",
    "    input_data_dir = \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/nano-confinement/surrogate_AL/data/\"\n",
    "    conf_list = [\"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/nano-confinement/rose_exp_1/config/gpr.yaml\", \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/nano-confinement/rose_exp_1/config/gpr_01.yaml\"]\n",
    "    pipeline_dir_list = [\"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/nano-confinement/rose_exp_1/experiment/test_04\", \"/pscratch/sd/u/usatlas/globus-compute-test/Tianle_test/nano-confinement/rose_exp_1/experiment/test_05\"]\n",
    "    for config_file, pipeline_dir in zip(conf_list, pipeline_dir_list):\n",
    "        submitted_pipelines.append(async_pipeline(model=model, input_data_dir=input_data_dir, config_file=config_file, pipeline_dir=pipeline_dir, num_iter=10, num_new_samples=10))\n",
    "    [p.result() for p in submitted_pipelines]\n",
    "\n",
    "teach()\n",
    "engine.shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f720970-7774-48bb-9ac4-e94bc8a3438c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python ROSE conda env",
   "language": "python",
   "name": "rose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
